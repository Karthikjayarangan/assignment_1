{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMELzqykpAHPSvs2ju0jwQj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karthikjayarangan/assignment_1/blob/main/Web_scrapping_of_Redbus_site_0307.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGmnCEuyBLOG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import requests,openpyxl\n",
        "\n",
        "try:\n",
        "  # URL to scrape\n",
        "  url = \"https://www.redbus.in/search?fromCityName=CMBT,%20Chennai,%20Chennai&fromCityId=66065&srcCountry=IND&toCityName=Bangalore&toCityId=122&destCountry=IND&onward=4-Jul-2024&opId=0&busType=Any\"\n",
        "\n",
        "  # Headers to mimic a browser visit\n",
        "  headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "  }\n",
        "\n",
        "  # Send a GET request to the URL\n",
        "  response = requests.get(url, headers=headers)\n",
        "\n",
        "  # Check if the request was successful\n",
        "  if response.status_code == 200:\n",
        "    # Parse the HTML content\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # List to store bus details\n",
        "    bus_details = []\n",
        "\n",
        "    # Example: extracting bus names, timings, prices, etc.\n",
        "    buses = soup.find_all('div', class_='clearfix bus-item-details')\n",
        "\n",
        "    for bus in buses:\n",
        "        bus_name = bus.find('div', class_='travels lh-24 f-bold d-color').text.strip()\n",
        "        departure_time = bus.find('div', class_='dp-time f-19 d-color f-bold').text.strip()\n",
        "        arrival_time = bus.find('div', class_='bp-time f-19 d-color disp-Inline').text.strip()\n",
        "        duration = bus.find('div', class_='dur l-color').text.strip()\n",
        "        bus_type = bus.find('div', class_='bus-type').text.strip()\n",
        "        price = bus.find('span', class_='f-19 f-bold').text.strip()\n",
        "\n",
        "        bus_details.append([bus_name, departure_time, arrival_time, duration, bus_type, price])\n",
        "\n",
        "    # Convert the list to a DataFrame\n",
        "    df = pd.DataFrame(bus_details,\n",
        "                      columns=['Bus Name', 'Departure Time', 'Arrival Time', 'Duration', 'Bus Type', 'Price'])\n",
        "\n",
        "    # Save to a CSV file\n",
        "    df.to_csv('bus_details.csv', index=False)\n",
        "    print(\"Bus details saved to 'bus_details.csv'\")\n",
        "  else:\n",
        "    print(\"Failed to retrieve the webpage. Status code:\", response.status_code)\n",
        "\n",
        "except Exception as e:\n",
        "     print(e)\n"
      ]
    }
  ]
}